{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import slampy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params\n",
    "the configuration attribute of the algorithm can be found in the setting.yaml file,\n",
    "you can change this file in order to execute different algorithm with different options\n",
    "\n",
    "**image_folder** is the root folder of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'Dataset/image_02'\n",
    "setting_file ='settings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the system with the **setting_file** and the type of the sensor in this case monocular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = slampy.System(setting_file,slampy.Sensor.MONOCULAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the images\n",
    "in this example we use the KITTI dataset, the images is not provided you can download it , in utils.py is also provide the method for read the TUM images named **load_images_TUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filenames, timestamps = load_images_KITTI(image_folder)\n",
    "num_images = len(image_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the algorithm with the load dataset and plot the depth map found in each frame if the tracking is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('images in the sequences {}'.format(num_images))\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "for idx in range(num_images):\n",
    "    # load and convert to RGB image \n",
    "    name = image_filenames[idx]\n",
    "    image = cv2.imread(name)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"failed to load image at {0}\".format(self.idx))\n",
    "        exit\n",
    "    t1 = time.time()\n",
    "    state = app.process_image_mono(image,timestamps[idx])\n",
    "    t2 = time.time()\n",
    "    if state == slampy.State.OK:\n",
    "        #get the depth\n",
    "        depth = app.get_depth()\n",
    "        #plot the figure\n",
    "        fig.suptitle('result of image {}'.format(idx))\n",
    "        ax.imshow(depth,cmap='magma')\n",
    "        fig.canvas.draw()\n",
    "        \n",
    "    #sleep the execution if the time is less than the image acquisition\n",
    "    ttrack = t2 - t1\n",
    "    t = 0\n",
    "    if idx < num_images - 1:\n",
    "        t = timestamps[idx + 1] - timestamps[idx]\n",
    "    elif idx > 0:\n",
    "        t = timestamps[idx] - timestamps[idx - 1]\n",
    "\n",
    "    if ttrack < t:\n",
    "        time.sleep(t - ttrack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
